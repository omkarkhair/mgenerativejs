/* eslint new-cap: 0 */
// var debug = require('debug')('mgenerate:text');
var axios = require('axios');

/**
 * $text returns a text generated by a large language model (llm) served through an ollama endpoint
 * Ollama endpoint and model must be configured as a environment variables MGENERATIVEJS_OLLAMA_ENDPOINT
 * and MGENERATIVE_OLLAMA_MODEL respectively
 *
 * @param  {Function} evaluator   evaluator function, passed in for every operator
 * @param  {Object} options       options to configure the array operator
 * @return {String}               Generated text
 */
module.exports = async function(evaluator, options) {
  // Configure client for Ollama endpoint
  const ollamaEndpoint = process.env.MGENERATIVEJS_OLLAMA_ENDPOINT;
  const model = process.env.MGENERATIVE_OLLAMA_MODEL;

  const ollamaClient = axios.create({
    baseURL: ollamaEndpoint,
    timeout: 30000
  });

  // Augment user prompt
  let prompt = `Please generate a ${options.prompt} `;
  if (options.maxWordCount && options.minWordCount) {
    prompt += `with a word count between {minWordCount} and {maxWordCount}`;
  } else if (options.maxWordCount) {
    prompt += `with a word count less than ${options.maxWordCount}`;
  } else if (options.minWordCount) {
    prompt += `with a word count greater than ${options.minWordCount}`;
  }
  prompt += `. `;
  prompt += `Ensure the response contains only the requested text without any additional commentary or conversational elements.`;

  // Generate text from Ollama
  let response = await ollamaClient.post('/generate', {
    model: model,
    prompt: prompt,
    stream: false
  });

  return response.data.response;
};
